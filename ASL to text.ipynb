{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(width, height, depth, classes):\n",
    "\tmodel = Sequential()\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tinputShape = (depth, height, width)\n",
    "\t\tchanDim = 1\n",
    "            \n",
    "\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\tinput_shape=inputShape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "        \n",
    "\tmodel.add(Dense(classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"C:/Users/DELL/Desktop/asl_dataset\"\n",
    "p = \"C:/Users/DELL/Desktop\"\n",
    "m = \"C:/Users/DELL/Desktop/asl_dataset/model.h5\"\n",
    "lab_bin = \"C:/Users/DELL/Desktop/asl_dataset/labelbin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "imagePaths = sorted(list(paths.list_images(d)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.2, random_state=42)\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "model = build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(\n",
    "\tx=aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing network...\")\n",
    "model.save(m, save_format=\"h5\")\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(lab_bin, \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "N = EPOCHS\n",
    "\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFile():\n",
    "    filename = filedialog.askopenfilename(initialdir=\"C:/Users/DELL/Desktop/asl_dataset\",\n",
    "                                          title=\"Select file\", filetypes=[(\"image\", \"*.jpg\"),\n",
    "                                                                          (\"image\", \"*.jpeg\"),\n",
    "                                                                          (\"image\", \"*.png\")])\n",
    "    global i\n",
    "    i = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "\n",
    "canvas = tk.Canvas(root, height=100, width=150, bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "frame = tk.Frame(root, bg=\"white\")\n",
    "frame.place(relwidth=0.8, relheight=0.6, relx=0.1, rely=0.1)\n",
    "\n",
    "openFile = tk.Button(root, text=\"Open File\", padx=10, pady=5, fg=\"white\", bg=\"#263D42\", command=addFile)\n",
    "openFile.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "[INFO] x: 99.99%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i = input(\"Enter file location of image: \")\n",
    "\n",
    "image = cv2.imread(i)\n",
    "output = image.copy()\n",
    "\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(m)\n",
    "l = pickle.loads(open(lab_bin, \"rb\").read())\n",
    "\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = l.classes_[idx]\n",
    "filename = i[i.rfind(os.path.sep) + 1:]\n",
    "label = \"{}: {:.2f}%\".format(label, proba[idx] * 100)\n",
    "\n",
    "output = imutils.resize(output, width=400)\n",
    "cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    "\n",
    "print(\"[INFO] {}\".format(label))\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
